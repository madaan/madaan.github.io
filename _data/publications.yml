- title: "Could you give me a hint? Generating inference graphs for defeasible reasoning"
  authors: "Aman Madaan, Dheeraj Rajagopal, Niket Tandon, Yiming Yang, and Eduard Hovy"
  conference: "ACL 2021 (Findings)"
  year: 2021
  organization: '<a href="https://2021.aclweb.org//>ACL</a>'
  pdf: "https://aclanthology.org/2021.findings-acl.456.pdf"
  talk: "https://madaan.github.io/res/presentations/cygmah.pdf"
  abstract: "Defeasible reasoning is the mode of reasoning where conclusions can be overturned by taking into account new evidence. A commonly used method in cognitive science and logic literature is to handcraft argumentation supporting inference graphs. While humans find inference graphs very useful for reasoning, constructing them at scale is difficult. In this paper, we automatically generate such inference graphs through transfer learning from another NLP task that shares the kind of reasoning that inference graphs support. Through automated metrics and human evaluation, we find that our method generates meaningful graphs for the defeasible inference task. Human accuracy on this task improves by 20% by consulting the generated graphs. Our findings open up exciting new research avenues for cases where machine reasoning can help human reasoning."
  org: ACL

- title: "Neural language modeling for contextualized temporal graph generation"
  authors: "Aman Madaan and Yiming Yang"
  conference: "NAACL 2021"
  year: 2021
  organization: '<a href="https://2021.naacl.org/>NAACL</a>'
  pdf: "https://www.aclweb.org/anthology/2021.naacl-main.67.pdf"
  talk: "https://madaan.github.io/res/presentations/naacl_temporal_gen.pdf"
  tldr: "https://madaan.github.io/res/tldr/graph_gen_tldr.jpg"
  abstract: "This paper presents the first study on using large-scale pre-trained language models for automated generation of an event-level temporal graph for a document. Despite the huge success of neural pre-training methods in NLP tasks, its potential for temporal reasoning over event graphs has not been sufficiently explored. Part of the reason is the difficulty in obtaining large training corpora with human-annotated events and temporal links. We address this challenge by using existing IE/NLP tools to automatically generate a large quantity (89,000) of system-produced document-graph pairs, and propose a novel formulation of the contextualized graph generation problem as a sequence-to-sequence mapping task. These strategies enable us to leverage and fine-tune pre-trained language models on the system-induced training data for the graph generation task. Our experiments show that our approach is highly effective in generating structurally and semantically valid graphs. Further, evaluation on a challenging hand-labeled, out-domain corpus shows that our method outperforms the closest existing method by a large margin on several metrics. Code and pre-trained models are available at https://github.com/madaan/temporal-graph-gen."
  org: NAACL

- title: "EIGEN: Event influence generation using pre-trained language models" 
  authors: "Aman Madaan, Dheeraj Rajagopal, Yiming Yang, Abhilasha Ravichander, Eduard Hovy, and Shrimai Prabhumoye."
  conference: "ArXiv"
  year: 2020
  pdf: "https://arxiv.org/pdf/2010.11764.pdf"
  abstract: "Reasoning about events and tracking their influences is fundamental to understanding processes. In this paper, we present EIGEN - a method to leverage pre-trained language models to generate event influences conditioned on a context, nature of their influence, and the distance in a reasoning chain. We also derive a new dataset for research and evaluation of methods for event influence generation. EIGEN outperforms strong baselines both in terms of automated evaluation metrics (by 10 ROUGE points) and human judgments on closeness to reference and relevance of generations. Furthermore, we show that the event influences generated by EIGEN improve the performance on a 'what-if' Question Answering (WIQA) benchmark (over 3% F1), especially for questions that require background knowledge and multi-hop reasoning."
  org: ArXiv

- title: "Politeness Transfer: A Tag and Generate Approach" 
  authors: "Aman Madaan, Amrith Setlur, Tanmay Parekh, Barnabas Poczos, Graham Neubig, Yiming Yang, Ruslan Salakhutdinov, Alan W. Black, and Shrimai Prabhumoye."
  conference: "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics"
  year: 2020
  pdf: "https://www.aclweb.org/anthology/2020.acl-main.169.pdf"
  abstract: "This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate."
  org: ACL

- title: "Practical Comparable Data Collection for Low-Resource Languages via Images" 
  authors: "Aman Madaan, Shruti Rijhwani, Antonios Anastasopoulos, Yiming Yang, and Graham Neubig"
  conference: "Proceedings of the Practical ML for Developing Countries Workshop, ICLR 2020"
  year: 2020
  pdf: "https://arxiv.org/pdf/2004.11954.pdf"
  abstract: "We propose a method of curating high-quality comparable training data for low-resource languages with monolingual annotators. Our method involves using a carefully selected set of images as a pivot between the source and target languages by getting captions for such images in both languages independently. Human evaluations on the English-Hindi comparable corpora created with our method show that 81.1% of the pairs are acceptable translations, and only 2.47% of the pairs are not translations at all. We further establish the potential of the dataset collected through our approach by experimenting on two downstream tasks - machine translation and dictionary extraction. All code and data are available at https://github.com/madaan/PML4DC-Comparable-Data-Collection"
  org: PML4DC@ICLR

- title: "Numerical Relation Extraction with Minimal Supervision"
  authors: "Aman Madaan and Ashish Mittal, Ganesh Ramakrishnan, and Sunita Sarawagi"
  conference: "Thirtieth AAAI Conference on Artificial Intelligence"
  year: 2016
  organization: '<a href="https://www.aaai.org/">AAAI</a>'
  pdf: "https://homes.cs.washington.edu/~mausam/papers/aaai16a.pdf"
  abstract: "We study a novel task of numerical relation extraction with the goal of extracting relations where one of the arguments is a number or a quantity ( e.g., atomic_number(Aluminium, 13), inflation_rate(India, 10.9%)). This task presents peculiar challenges not found in standard IE, such as the difficulty of matching numbers in distant supervision and the importance of units. We design two extraction systems that require minimal human supervision per relation: (1) NumberRule, a rule based extractor, and (2) NumberTron, a probabilistic graphical model. We find that both systems dramatically outperform MultiR, a state-of-the-art non-numerical IE model, obtaining up to 25 points F-score improvement."
  publication: "https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12486"
  talk: "https://madaan.github.io/res/presentations/aaai-presentation-final.pdf"
  org: AAAI
  org-url: "https://www.aaai.org/"


- title: "Design and implementation of a high performance computing system using distributed compilation"
  authors: "Sunil Kr Singh, Aman Madaan, Ankur Aggarwal, and Ankur Dewan"
  conference: "Advances in Computing, Communications and Informatics (ICACCI)"
  year: 2013
  org: ICACCI
  org-url: http://icacci-conference.org/2018/
  pdf: "https://madaan.github.io/res/papers/distcc-cluster.pdf"
  publication: "https://ieeexplore.ieee.org/document/6637374"
  abstract: "The idea of using the idle resources of a system for some other useful purpose is not new. seti@home pioneered this concept of “public resource computing” by bringing together millions of users worldwide who were ready to donate their idle CPU cycles to the cause of searching the extra terrestrial intelligence. In this paper, we describe a system that uses the same concept for reducing build times by using free cycles on idle computer systems in computer labs of our institute. The challenge of distributing compilation is tackled by a distributing compiler. We use distcc for the purpose. The challenge then is to design a system that keeps track of free helpers, dividing the work fairly among the helpers and most importantly, providing an intuitive interface to the clients who would use the system oblivious of the complexities of the back end."
