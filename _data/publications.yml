- title: "Self-Refine: Iterative Refinement with Self-Feedback"
  year: 2023
  authors: "Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Sean Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, Amir Yazdanbakhsh, Peter Clark."
  conference: "Conference on Neural Information Processing Systems (\textbf{NeurIPS})"
  org: NeurIPS
  code: https://selfrefine.info/
  abstract: "Self-Refine is a novel approach that allows LLMs to iteratively refine outputs and incorporate feedback along multiple dimensions to improve performance on diverse tasks. Unlike prior work, it does not require supervised training data or reinforcement learning, and works with a single LLM."
  pdf: "https://arxiv.org/pdf/2303.17651.pdf"

- title: "Bridging the gap: A survey on integrating (human) feedback for natural language generation"
  year: 2023
  authors: "Patrick Fernandes, Aman Madaan, Emmy Liu, António Farinhas, Pedro Henrique Martins, Amanda Bertsch, José G. C. de Souza, Shuyan Zhou, Tongshuang Wu, Graham Neubig, André F. T. Martins"
  conference: "Transactions of the Association for Computational Linguistics"
  org: TACL
  abstract: "Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention."
  pdf: "https://arxiv.org/abs/2305.00955"


- title: "PAL: Program-aided Language Models"
  year: 2023
  authors: "Luyu Gao*, Aman Madaan*, Shuyan Zhou*, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig"
  conference: "International Conference on Machine Learning"
  org: ICML
  code: https://reasonwithpal.com/
  abstract: "We present Program-Aided Language models (PAL): a new method that uses the LLM to read natural language problems and generate programs as the intermediate reasoning steps, but offloads the solution step to a programmatic runtime such as a Python interpreter."
  pdf: "https://arxiv.org/abs/2211.10435"


- title: "Learning Performance Improving Code Edits"
  year: 2023
  authors: "Aman Madaan, Alexander Shypula, Uri Alon, Milad Hashemi, Parthasarathy Ranganathan, Yiming Yang, Graham Neubig, Amir Yazdanbakhsh"
  conference: "Deep Learning for Code at ICLR 2023"
  org: DL4C@ICLR
  code: https://pie4perf.com/
  abstract: "The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods to achieve continued performance gains. To optimize program efficiency, programmers must craft and refactor code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance-improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. To evaluate and improve the capacity of large language models, we have curated a large-scale dataset of Performance-Improving Edits (PIE). PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. Our results show that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs. Moreover, PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task."
  pdf: "https://arxiv.org/pdf/2302.07867.pdf"



- title: "Language Models of Code are Few-Shot Commonsense Learners"
  year: 2022
  authors: "Aman Madaan, Shuyan Zhou, Uri Alon, Yiming Yang, Graham Neubig"
  conference: "EMNLP 2022"
  org: EMNLP
  code: https://github.com/madaan/CoCoGen
  abstract: "We address the general task of structured commonsense reasoning: given a natural language input, the goal is to generate a graph such as an event- or a reasoning-graph. To employ large language models (LMs) for this task, existing approaches ``serialize'' the output graph as a flat list of nodes and edges. Although feasible, these serialized graphs strongly deviate from the natural language corpora that LMs were pre-trained on, hindering LMs from generating them correctly.  In this paper, we show that when we instead frame structured commonsense reasoning tasks as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than LMs of natural language, even when the downstream task does not involve source code at all. We demonstrate our approach across three diverse structured commonsense reasoning tasks. In all these natural language tasks, we show that using our approach, a code generation LM (CODEX) outperforms natural-LMs that are fine-tuned on the target task (e.g., T5) and other strong LMs such as GPT-3 in the few-shot setting."
  pdf: "https://arxiv.org/pdf/2210.07128.pdf"
  talk: https://youtu.be/_Wr8pjS-748?t=22



- title: "Conditional set generation using Seq2seq models"
  year: 2022
  authors: "Aman Madaan, Dheeraj Rajagopal, Niket Tandon, Yiming Yang, and Antoine Bosselut"
  conference: "EMNLP 2022"
  org: EMNLP
  abstract: "Conditional set generation learns a mapping from an input sequence of tokens to a set. Several NLP tasks, such as entity typing and dialogue emotion tagging, are instances of set generation. Sequence-to-sequence~(Seq2seq) models are a popular choice to model set generation, but they treat a set as a sequence and do not fully leverage its key properties, namely order-invariance and cardinality. We propose a novel algorithm for effectively sampling informative orders over the combinatorial space of label orders. Further, we jointly model the set cardinality and output by adding the set size as the first element and taking advantage of the autoregressive factorization used by Seq2seq models. Our method is a model-independent data augmentation approach that endows any Seq2seq model with the signals of order-invariance and cardinality. Training a Seq2seq model on this new augmented data~(without any additional annotations) gets an average relative improvement of 20% for four benchmarks datasets across models spanning from BART-base, T5-xxl, and GPT-3."
  pdf: "https://arxiv.org/pdf/2205.12485.pdf"

- title: "Memory-assisted prompt editing to improve GPT-3 after deployment"
  year: 2022
  authors: "Aman Madaan*, Niket Tandon*, Peter Clark, and Yiming Yang"
  conference: "EMNLP 2022"
  org: EMNLP
  code: https://github.com/madaan/memprompt
  abstract: "Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans. For example, GPT-3 would mistakenly interpret 'What word is similar to good?' to mean a homophone, while the user intended a synonym. Our goal is to effectively correct such errors via user interactions with the system but without retraining, which will be prohibitively costly. We pair GPT-3 with a growing memory of recorded cases where the model misunderstood the user's intents, along with user feedback for clarification. Such a memory allows our system to produce enhanced prompts for any new query based on the user feedback for error correction on similar cases in the past. On four tasks (two lexical tasks, two  advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3. Our approach is a step towards the low-cost utility enhancement for very large pre-trained LMs."
  pdf: "https://arxiv.org/pdf/2201.06009.pdf"
  talk: https://www.youtube.com/watch?v=Ld7R02bOiNQ
  blog: https://blog.allenai.org/introducing-memprompt-55c8f6935a5b



- title: "FLOWGEN: Fast and slow graph generation"
  year: 2022
  authors: "Aman Madaan and Yiming Yang"
  conference: "Dynamic Neural Networks Workshop at ICML 2022"
  org: Dynn@ICML
  abstract: "Machine learning models typically exert the same computational power on both easy and challenging examples. This is in stark contrast with humans, who use either fast (instinctive) or slow (analytical) thinking depending on the problem difficulty, a property called the dual-process theory of mind. We present FLOWGEN, a graph-generation model inspired by the dual-process theory of mind that generates large graphs incrementally. Depending on the difficulty of completing the graph at the current step, graph generation is routed to either a fast (weaker) or a slow (stronger) model. The fast and slow models have identical architectures, but vary in the number of parameters and consequently the strength. Experiments on real-world graphs show that ours can successfully generate graphs similar to those generated by a single large model in a fraction of time."
  pdf: "https://arxiv.org/pdf/2207.07656.pdf"

- title: "Learning to Repair: Repairing model output errors after deployment using a dynamic memory of feedback"
  year: 2022
  authors: "Niket Tandon*, Aman Madaan*, Peter Clark, and Yiming Yang"
  conference: "NAACL 2022 (Findings)"
  org: NAACL
  abstract: "Large language models (LMs), while powerful, are not immune to mistakes, but can be difficult to retrain. Our goal is for an LM to continue to improve after deployment, without retraining, using feedback from the user. Our approach pairs an LM with (i) a growing memory of cases where the user identified an output error and provided general feedback on how to correct it (ii) a corrector model, trained to translate this general feedback into specific edits to repair the model output. Given a new, unseen input, our model can then use feedback from similar, past cases to repair output errors that may occur. We instantiate our approach using an existing, fixed model for script generation, that takes a goal (e.g., 'bake a cake') and generates a partially ordered sequence of actions to achieve that goal, sometimes containing errors. Our memory-enhanced system, FBNet, learns to apply user feedback to repair such errors (up to 30 points improvement), while making a start at avoiding similar past mistakes on new, unseen examples (up to 7 points improvement in a controlled setting). This is a first step towards strengthening deployed models, potentially broadening their utility."
  pdf: "https://arxiv.org/pdf/2112.09737.pdf"
  code: https://github.com/allenai/interscript


- title: "CURIE: An Iterative Querying Approach for Reasoning About Situations" 
  authors: "Aman Madaan*, Dheeraj Rajagopal*, Yiming Yang, Abhilasha Ravichander, Eduard Hovy, and Shrimai Prabhumoye."
  conference: "Workshop on Commonsense Representation and Reasoning (CSRR) @ ACL 2022"
  year: 2022
  pdf: "https://aclanthology.org/2022.csrr-1.7.pdf"
  abstract: "Recently, models have been shown to predict the effects of unexpected situations, e.g., would cloudy skies help or hinder plant growth? Given a context, the goal of such situational reasoning is to elicit the consequences of a new situation (st) that arises in that context. We propose a method to iteratively build a graph of relevant consequences explicitly in a structured situational graph (st-graph) using natural language queries over a finetuned language model (M). Across multiple domains, CURIE generates st-graphs that humans find relevant and meaningful in eliciting the consequences of a new situation. We show that st-graphs generated by CURIE improve a situational reasoning end task (WIQA-QA) by 3 points on accuracy by simply augmenting their input with our generated situational graphs, especially for a hard subset that requires background knowledge and multi-hop reasoning."
  org: CSRR@ACL
  code: https://github.com/dheerajrajagopal/EIGEN

- title: "Think about it! Improving defeasible reasoning by first modeling the question scenario"
  authors: "Aman Madaan, Niket Tandon, Dheeraj Rajagopal, Peter Clark, Yiming Yang, and Eduard Hovy"
  conference: "EMNLP 2021"
  year: 2021
  organization: '<a href="https://2021.emnlp.org//>EMNLP</a>' 
  pdf: "https://arxiv.org/pdf/2110.12349.pdf" 
  abstract: "Defeasible reasoning is the mode of reasoning where conclusions can be overturned by taking into account new evidence. Existing cognitive science literature on defeasible reasoning suggests that a person forms a mental model of the problem scenario before answering questions. Our research goal asks whether neural models can similarly benefit from envisioning the question scenario before answering a defeasible query. Our approach is, given a question, to have a model first create a graph of relevant influences, and then leverage that graph as an additional input when answering the question. Our system, CURIOUS, achieves a new state-of-the-art on three different defeasible reasoning datasets. This result is significant as it illustrates that performance can be improved by guiding a system to 'think about' a question and explicitly model the scenario, rather than answering reflexively."
  org: EMNLP
  code: https://github.com/madaan/thinkaboutit

- title: "Could you give me a hint? Generating inference graphs for defeasible reasoning"
  authors: "Aman Madaan*, Dheeraj Rajagopal*, Niket Tandon*, Yiming Yang, and Eduard Hovy"
  conference: "ACL 2021 (Findings)"
  year: 2021
  organization: '<a href="https://2021.aclweb.org//>ACL</a>'
  pdf: "https://aclanthology.org/2021.findings-acl.456.pdf"
  talk: "https://madaan.github.io/res/presentations/cygmah.pdf"
  abstract: "Defeasible reasoning is the mode of reasoning where conclusions can be overturned by taking into account new evidence. A commonly used method in cognitive science and logic literature is to handcraft argumentation supporting inference graphs. While humans find inference graphs very useful for reasoning, constructing them at scale is difficult. In this paper, we automatically generate such inference graphs through transfer learning from another NLP task that shares the kind of reasoning that inference graphs support. Through automated metrics and human evaluation, we find that our method generates meaningful graphs for the defeasible inference task. Human accuracy on this task improves by 20% by consulting the generated graphs. Our findings open up exciting new research avenues for cases where machine reasoning can help human reasoning."
  org: ACL
  code: https://github.com/madaan/defeasible_graphs

- title: "Neural language modeling for contextualized temporal graph generation"
  authors: "Aman Madaan and Yiming Yang"
  conference: "NAACL 2021"
  year: 2021
  organization: '<a href="https://2021.naacl.org/>NAACL</a>'
  pdf: "https://www.aclweb.org/anthology/2021.naacl-main.67.pdf"
  talk: "https://madaan.github.io/res/presentations/naacl_temporal_gen.pdf"
  tldr: "https://madaan.github.io/res/tldr/graph_gen_tldr.jpg"
  abstract: "This paper presents the first study on using large-scale pre-trained language models for automated generation of an event-level temporal graph for a document. Despite the huge success of neural pre-training methods in NLP tasks, its potential for temporal reasoning over event graphs has not been sufficiently explored. Part of the reason is the difficulty in obtaining large training corpora with human-annotated events and temporal links. We address this challenge by using existing IE/NLP tools to automatically generate a large quantity (89,000) of system-produced document-graph pairs, and propose a novel formulation of the contextualized graph generation problem as a sequence-to-sequence mapping task. These strategies enable us to leverage and fine-tune pre-trained language models on the system-induced training data for the graph generation task. Our experiments show that our approach is highly effective in generating structurally and semantically valid graphs. Further, evaluation on a challenging hand-labeled, out-domain corpus shows that our method outperforms the closest existing method by a large margin on several metrics. Code and pre-trained models are available at https://github.com/madaan/temporal-graph-gen."
  org: NAACL
  code: https://github.com/madaan/temporal-graph-gen


- title: "Towards Using Heterogeneous Relation Graphs for End-to-End TTS"
  authors: "Amrith Setlur*, Aman Madaan*, Tanmay Parekh*, Yiming Yang, and Alan W. Black"
  conference: "ASRU 2021"
  year: 2021
  organization: '<a href="https://ieeexplore.ieee.org/xpl/conhome/9687821/proceeding/>ASRU</a>'
  pdf: "http://www.cs.cmu.edu/~awb/papers/ASRU2021_setlur.pdf"
  org: ASRU
  abstract: "Neural models for end-to-end text-to-speech (TTS) synthesis are increasingly outperforming traditional approaches in statistical parametric speech synthesis.
Speech generation in these neural models predominantly relies on using free-form text as the input modality. However, the earlier statistical parametric models were built on encoded phonetic and syntactic features. 
In this work, we explore the possibility of explicitly feeding deterministic linguistic structure to a neural TTS system in the form of Heterogeneous Relational Graphs (HRGs), an expressive formalism capable of representing phonetic and syntactic information. 
Specifically, we use Graph Convolutional Networks to learn structurally informed continuous representations of the HRGs, which can be seamlessly passed to the encoders of popular neural TTS models like TransformerTTS or Tacotron. Furthermore, our simple HRG based text-to-speech synthesis leverages the syntactic bias in HRGs as demonstrated by improvements in automated metrics and human evaluation on (i) the single speaker dataset LJSpeech; (ii) the multi-speaker dataset Arctic; and (iii) out-of-domain test sets from the Blizzard challenge."

- title: "Politeness Transfer: A Tag and Generate Approach" 
  authors: "Aman Madaan*, Amrith Setlur*, Tanmay Parekh*, Barnabas Poczos, Graham Neubig, Yiming Yang, Ruslan Salakhutdinov, Alan W. Black, and Shrimai Prabhumoye."
  conference: "ACL 2020"
  year: 2020
  pdf: "https://www.aclweb.org/anthology/2020.acl-main.169.pdf"
  talk: "https://madaan.github.io/res/presentations/tag_and_generate.pdf"
  abstract: "This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate."
  org: ACL
  code: https://github.com/tag-and-generate

- title: "Practical Comparable Data Collection for Low-Resource Languages via Images" 
  authors: "Aman Madaan, Shruti Rijhwani, Antonios Anastasopoulos, Yiming Yang, and Graham Neubig"
  conference: "Proceedings of the Practical ML for Developing Countries Workshop, ICLR 2020"
  year: 2020
  pdf: "https://arxiv.org/pdf/2004.11954.pdf"
  abstract: "We propose a method of curating high-quality comparable training data for low-resource languages with monolingual annotators. Our method involves using a carefully selected set of images as a pivot between the source and target languages by getting captions for such images in both languages independently. Human evaluations on the English-Hindi comparable corpora created with our method show that 81.1% of the pairs are acceptable translations, and only 2.47% of the pairs are not translations at all. We further establish the potential of the dataset collected through our approach by experimenting on two downstream tasks - machine translation and dictionary extraction. All code and data are available at https://github.com/madaan/PML4DC-Comparable-Data-Collection"
  talk: "https://pml4dc.github.io/iclr2020/pdf/PML4DC2020_27.pdf"
  org: PML4DC@ICLR
  code: https://github.com/madaan/PML4DC-Comparable-Data-Collection

- title: "Numerical Relation Extraction with Minimal Supervision"
  authors: "Aman Madaan, Ashish Mittal, Mausam, Ganesh Ramakrishnan, and Sunita Sarawagi"
  conference: "AAAI 2016"
  year: 2016
  organization: '<a href="https://www.aaai.org/">AAAI</a>'
  pdf: "https://homes.cs.washington.edu/~mausam/papers/aaai16a.pdf"
  abstract: "We study a novel task of numerical relation extraction with the goal of extracting relations where one of the arguments is a number or a quantity ( e.g., atomic_number(Aluminium, 13), inflation_rate(India, 10.9%)). This task presents peculiar challenges not found in standard IE, such as the difficulty of matching numbers in distant supervision and the importance of units. We design two extraction systems that require minimal human supervision per relation: (1) NumberRule, a rule based extractor, and (2) NumberTron, a probabilistic graphical model. We find that both systems dramatically outperform MultiR, a state-of-the-art non-numerical IE model, obtaining up to 25 points F-score improvement."
  publication: "https://www.aaai.org/ocs/index.php/AAAI/AAAI16/paper/view/12486"
  talk: "https://madaan.github.io/res/presentations/aaai-presentation-final.pdf"
  org: AAAI
  org-url: "https://www.aaai.org/"


- title: "Design and implementation of a high performance computing system using distributed compilation"
  authors: "Sunil Kr Singh, Aman Madaan, Ankur Aggarwal, and Ankur Dewan"
  conference: "Advances in Computing, Communications and Informatics (ICACCI)"
  year: 2013
  org: ICACCI
  org-url: http://icacci-conference.org/2018/
  pdf: "https://madaan.github.io/res/papers/distcc-cluster.pdf"
  publication: "https://ieeexplore.ieee.org/document/6637374"
  abstract: "The idea of using the idle resources of a system for some other useful purpose is not new. seti@home pioneered this concept of “public resource computing” by bringing together millions of users worldwide who were ready to donate their idle CPU cycles to the cause of searching the extra terrestrial intelligence. In this paper, we describe a system that uses the same concept for reducing build times by using free cycles on idle computer systems in computer labs of our institute. The challenge of distributing compilation is tackled by a distributing compiler. We use distcc for the purpose. The challenge then is to design a system that keeps track of free helpers, dividing the work fairly among the helpers and most importantly, providing an intuitive interface to the clients who would use the system oblivious of the complexities of the back end."
